# Overview of the data
## data sources
### items_only.csv
This file is a flat list of all items in the data (no series, subseries, etc.) that was generated by combining excel sheets provided by ICJ and remediated using OpenRefine. A copy of it is uploaded to Google Drive.
### aspace_uploader.xlsx
The Excel upload template provided by the ArchivesSpace uploader plugin developers for uploading archival objects. Not used, but provided for reference.
### aspace_headers.xslx
A minimal version of the required headers for uploading, generated from aspace_uploader.xlsx. The mysterious black-bordered cells in the first row have to be copied manually into each uploader spreadsheet in `uploaders/` in order for the upload to succeed.
### bulk_import_template.csv
A .csv version of the aspace_headers.xlsx. Used for its headers, which are prepended to generated CSV data. Note that the "mystery row" of black-bordered headers ceases to function when converted to .csv.
### series/
CSV files for each of the series in the data, after processing using the first three scripts listed below. Not used for uploading because the version of the ArchivesSpace uploader plugin used on our VM doesn't support CSV uploads.
### uploaders/
Excel uploader files for each of the series in the data. For unknown reasons, the first row in each of these sheets has to be copy-pasted from the aspace_headers.xlsx template file — even though the row is empty. Otherwise, the upload will fail with errors about being unable to create the top container for each item. The "magic" row has black borders around each of its cells.
## scripts
### split_by_series.py
Takes a single input file (hardcoded to items_only.csv) and splits it into multiple .csv files, one for each series, using the value in the "dc:type" column. The output files are named after the series and placed in the (hardcoded) `series` directory.
### add_hierarchy.py
Takes a single input file or directory path as its only argument, and operates on all .csv files found. Generates rows in the data for series, subseries, and file-level information with logic specific to the data (e.g. Audio discs get files, but other subseries do not). ArchivesSpace requires some data in these rows that sets the hierarchy, including the "level" and "hierarchy" columns, so we autogenerate it. Overwrites all input files and renames them to *_hierarchy.csv.
### map_aspace_fields.py
Takes a single input file or directory path as its only argument, and operates on all .csv files found. Maps the columns in the data to ArchivesSpace fields and applies some custom logic to populate certain fields. Overwrites all input files and renames them to *_aspace.csv. Also prepends header rows to the top of each file taken from bulk_import_template.csv.
### csv2xlsx.py
Takes a single input file or directory path as its only argument, and operates on all .csv files found. Converts the .csv files to .xlsx files and outputs the .xlsx files to the same directory. Requires the `openpyxl` python library to be installed (e.g. `pip install openpyxl`).
### regenerate_all.sh
Runs the entire data pipeline, starting from the original items_only.csv file. Permanently deletes the series/ and uploaders/ directories and all files in them, then regenerates them from scratch. After this is done, you need to copy the "mystery" black-bordered headers from aspace_headers.xslx and paste them over the first (empty) row in each of the spreadsheets in uploaders. Here is the process step by step:
1. open aspace_headers.xlsx
2. in excel, click the number of the first row, which will select the entire row
3. copy (cmd/ctrl + c)
4. open the uploader sheet
5. click the number of the first row, which will select the entire row
6. paste (cmd/ctrl + v)
Sometimes it will warn you that the rows are different length but it shouldn't impact anything. The row in `aspace_headers.xlsx` doesn’t appear to have any actual data, but for me, the cells have black borders. When it works, after pasting, the place you pasted will take on the same black bordered appearance.
